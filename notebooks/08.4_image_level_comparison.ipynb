{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9229c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_image_level' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    117\u001b[39m OUT.parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    119\u001b[39m P_CLIP_SCENE = Path(\u001b[33m\"\u001b[39m\u001b[33moutputs/csv/clip_scene_subjects.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m df_per_image = one_row_per_image(\u001b[43mdf_image_level\u001b[49m, clip_scene_csv=P_CLIP_SCENE)\n\u001b[32m    122\u001b[39m df_per_image.to_csv(OUT, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    124\u001b[39m \u001b[38;5;28mprint\u001b[39m(OUT.as_posix())\n",
      "\u001b[31mNameError\u001b[39m: name 'df_image_level' is not defined"
     ]
    }
   ],
   "source": [
    "### 08.4. Output czytelny: 1 wiersz = 1 zdjęcie (zbiorcza tabela porównawcza)\n",
    "\n",
    "\"\"\"\n",
    "Tworzy tabelę porównawczą per-obraz:\n",
    "- YOLO: lista subjectów PL/EN\n",
    "- LVIS: lista subjectów PL/EN\n",
    "- OCR:  pełny tekst (full_text)\n",
    "- Human universal: ręczne sugestie (kolumna universal)\n",
    "- CLIP scene: subject_pl / subject_en + scene_score (z outputs/csv/clip_scene_subjects.csv)\n",
    "\n",
    "Wymaga: df_image_level (long) z kolumnami:\n",
    "file_name, source_model, type, label_en, label_pl, text\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _join_unique(series: pd.Series, sep: str = \"; \") -> str:\n",
    "    vals = series.dropna().astype(str).map(lambda x: x.strip())\n",
    "    vals = vals[vals.ne(\"\") & vals.ne(\"nan\")]\n",
    "    uniq = pd.unique(vals)\n",
    "    return sep.join(uniq.tolist())\n",
    "\n",
    "\n",
    "def _load_clip_scene_best(path_csv: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ładuje clip_scene_subjects.csv i wybiera najlepszą scenę per obraz (max scene_score).\n",
    "    Oczekiwane kolumny: file_name, subject_en, subject_pl, scene_score\n",
    "    Zwraca: file_name, scene_clip_pl, scene_clip_en, scene_clip_score\n",
    "    \"\"\"\n",
    "    if not path_csv.exists():\n",
    "        # brak pliku = brak kolumn sceny (nie wywalamy całej komórki)\n",
    "        return pd.DataFrame(columns=[\"file_name\", \"scene_clip_pl\", \"scene_clip_en\", \"scene_clip_score\"])\n",
    "\n",
    "    df = pd.read_csv(path_csv)\n",
    "    required = {\"file_name\", \"subject_en\", \"subject_pl\", \"scene_score\"}\n",
    "    if not required.issubset(df.columns):\n",
    "        raise ValueError(f\"CLIP scene: oczekiwano {sorted(required)}, jest: {list(df.columns)}\")\n",
    "\n",
    "    df[\"file_name\"] = df[\"file_name\"].astype(str).map(lambda x: Path(x).name)\n",
    "\n",
    "    best = (\n",
    "        df.sort_values(\"scene_score\", ascending=False)\n",
    "          .drop_duplicates(\"file_name\")\n",
    "          .loc[:, [\"file_name\", \"subject_pl\", \"subject_en\", \"scene_score\"]]\n",
    "          .rename(columns={\n",
    "              \"subject_pl\": \"scene_clip_pl\",\n",
    "              \"subject_en\": \"scene_clip_en\",\n",
    "              \"scene_score\": \"scene_clip_score\",\n",
    "          })\n",
    "    )\n",
    "    return best\n",
    "\n",
    "\n",
    "def one_row_per_image(df_image_level: pd.DataFrame, clip_scene_csv: Path | None = None) -> pd.DataFrame:\n",
    "    df = df_image_level.copy()\n",
    "\n",
    "    # 1) Obiekty: agregacja (YOLO/LVIS)\n",
    "    df_obj = df[df[\"type\"] == \"object\"].copy()\n",
    "    obj_agg = (\n",
    "        df_obj.groupby([\"file_name\", \"source_model\"])\n",
    "              .agg(\n",
    "                  objects_pl=(\"label_pl\", _join_unique),\n",
    "                  objects_en=(\"label_en\", _join_unique),\n",
    "              )\n",
    "              .reset_index()\n",
    "    )\n",
    "\n",
    "    obj_wide = obj_agg.pivot(index=\"file_name\", columns=\"source_model\", values=[\"objects_pl\", \"objects_en\"])\n",
    "    obj_wide.columns = [f\"{a}__{b}\" for a, b in obj_wide.columns]\n",
    "    obj_wide = obj_wide.reset_index()\n",
    "\n",
    "    # 2) Tekst: agregacja (OCR + human_universal)\n",
    "    df_txt = df[df[\"type\"] == \"text\"].copy()\n",
    "    txt_agg = (\n",
    "        df_txt.groupby([\"file_name\", \"source_model\"])[\"text\"]\n",
    "              .apply(lambda s: _join_unique(s, sep=\"\\n---\\n\"))\n",
    "              .reset_index(name=\"text_block\")\n",
    "    )\n",
    "    txt_wide = txt_agg.pivot(index=\"file_name\", columns=\"source_model\", values=\"text_block\").reset_index()\n",
    "\n",
    "    # 3) Merge obiekty + tekst\n",
    "    out = obj_wide.merge(txt_wide, on=\"file_name\", how=\"outer\")\n",
    "\n",
    "    # 4) Merge CLIP scene (opcjonalnie)\n",
    "    if clip_scene_csv is not None:\n",
    "        df_scene_best = _load_clip_scene_best(clip_scene_csv)\n",
    "        if not df_scene_best.empty:\n",
    "            out = out.merge(df_scene_best, on=\"file_name\", how=\"left\")\n",
    "\n",
    "    # 5) fillna tylko na kolumnach tekstowych\n",
    "    for c in out.columns:\n",
    "        if c != \"file_name\":\n",
    "            out[c] = out[c].fillna(\"\").astype(str)\n",
    "\n",
    "    # 6) TWARDY wybór kolumn (docelowy układ)\n",
    "    keep = [\n",
    "        \"file_name\",\n",
    "        \"human_universal\",\n",
    "        \"ocr\",\n",
    "        \"scene_clip_pl\",\n",
    "        \"scene_clip_en\",\n",
    "        \"scene_clip_score\",\n",
    "        \"objects_pl__yolo\", \"objects_en__yolo\",\n",
    "        \"objects_pl__lvis\", \"objects_en__lvis\",\n",
    "    ]\n",
    "    out = out.loc[:, [c for c in keep if c in out.columns]]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# --- OUTPUT + ZAPIS + PODGLĄD ---\n",
    "\n",
    "OUT = Path(\"outputs/csv/08.4_image_level_comparison.csv\")\n",
    "OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "P_CLIP_SCENE = Path(\"outputs/csv/clip_scene_subjects.csv\")\n",
    "\n",
    "df_per_image = one_row_per_image(df_image_level, clip_scene_csv=P_CLIP_SCENE)\n",
    "df_per_image.to_csv(OUT, index=False)\n",
    "\n",
    "print(OUT.as_posix())\n",
    "df_per_image.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv MetaLogic)",
   "language": "python",
   "name": "metalogic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

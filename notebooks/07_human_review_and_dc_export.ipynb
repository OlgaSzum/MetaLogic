{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c43f424",
   "metadata": {},
   "source": [
    "### 1. Importy + ścieżki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "264c9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. Importy i konfiguracja ścieżek\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, VBox, HBox, Output\n",
    "from PIL import Image\n",
    "\n",
    "PROJECT_ROOT = Path(\".\").resolve()\n",
    "ROOT = PROJECT_ROOT  # alias, żeby dalsze komórki mogły używać ROOT\n",
    "\n",
    "OUTPUT_CSV_DIR = PROJECT_ROOT / \"outputs\" / \"csv\"\n",
    "OUTPUT_CSV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Pomocnicza funkcja do rozbijania tekstów typu \"person; tie\"\n",
    "def clean_split(value: str):\n",
    "    if not isinstance(value, str):\n",
    "        return []\n",
    "    tmp = value.replace(\"(\", \";\").replace(\")\", \";\")\n",
    "    parts = [p.strip() for p in re.split(r\"[;,]\", tmp)]\n",
    "    return [p for p in parts if p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62199d",
   "metadata": {},
   "source": [
    "### 2. CLIP → df_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dacf1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07] CLIP kolumny: ['file_name', 'subject_en', 'subject_pl', 'scene_score']\n",
      "[07] df_clip shape: (74, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>subject_en</th>\n",
       "      <th>subject_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>shop interior</td>\n",
       "      <td>wnętrze sklepu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>crowd of people on the street</td>\n",
       "      <td>tłum na ulicy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009.jpg</td>\n",
       "      <td>graffiti or political slogans on walls</td>\n",
       "      <td>napisy lub hasła na murach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0022.jpg</td>\n",
       "      <td>street protest</td>\n",
       "      <td>demonstracja uliczna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0034.jpg</td>\n",
       "      <td>strollers or playgrounds</td>\n",
       "      <td>wózki dziecięce lub place zabaw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name                              subject_en  \\\n",
       "0  0004.jpg                           shop interior   \n",
       "1  0006.jpg           crowd of people on the street   \n",
       "2  0009.jpg  graffiti or political slogans on walls   \n",
       "3  0022.jpg                          street protest   \n",
       "4  0034.jpg                strollers or playgrounds   \n",
       "\n",
       "                        subject_pl  \n",
       "0                   wnętrze sklepu  \n",
       "1                    tłum na ulicy  \n",
       "2       napisy lub hasła na murach  \n",
       "3             demonstracja uliczna  \n",
       "4  wózki dziecięce lub place zabaw  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7.0 CLIP – wczytanie wyników z CSV\n",
    "\n",
    "clip_csv = OUTPUT_CSV_DIR / \"clip_scene_subjects.csv\"\n",
    "\n",
    "if not clip_csv.exists():\n",
    "    print(\"[07] Brak pliku:\", clip_csv)\n",
    "    df_clip = pd.DataFrame(columns=[\"file_name\", \"subject_en\", \"subject_pl\"])\n",
    "else:\n",
    "    df_raw = pd.read_csv(clip_csv)\n",
    "    print(\"[07] CLIP kolumny:\", list(df_raw.columns))\n",
    "\n",
    "    needed = {\"file_name\", \"subject_en\", \"subject_pl\"}\n",
    "    missing = needed - set(df_raw.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Brak kolumn w {clip_csv}: {missing}\")\n",
    "\n",
    "    # bierzemy tylko to, co potrzebne do kandydatów\n",
    "    df_clip = df_raw[[\"file_name\", \"subject_en\", \"subject_pl\"]].copy()\n",
    "    print(\"[07] df_clip shape:\", df_clip.shape)\n",
    "\n",
    "df_clip.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb8966",
   "metadata": {},
   "source": [
    "### 4. OCR → df_ocr (wersja prosta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2427ff02",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MetaLogic/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'file_path'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m rows = []\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df_ocr_raw.iterrows():\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     iid = \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     19\u001b[39m     text = row.get(\u001b[33m\"\u001b[39m\u001b[33mfull_text\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m extract_words(text):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MetaLogic/.venv/lib/python3.13/site-packages/pandas/core/series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MetaLogic/.venv/lib/python3.13/site-packages/pandas/core/series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MetaLogic/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'file_path'"
     ]
    }
   ],
   "source": [
    "### 7.2 OCR – pozyskanie słów jako subjectów (wersja prosta)\n",
    "\n",
    "ocr_csv = OUTPUT_CSV_DIR / \"ocr_results.csv\"\n",
    "\n",
    "if ocr_csv.exists():\n",
    "    df_ocr_raw = pd.read_csv(ocr_csv)\n",
    "else:\n",
    "    df_ocr_raw = pd.DataFrame(columns=[\"file_path\",\"full_text\"])\n",
    "\n",
    "def extract_words(text):\n",
    "    if not isinstance(text,str):\n",
    "        return []\n",
    "    # słowa ≥ 3 litery\n",
    "    return re.findall(r\"[A-Za-zĄąĆćĘęŁłŃńÓóŚśŻżŹź]{3,}\", text)\n",
    "\n",
    "rows = []\n",
    "for _, row in df_ocr_raw.iterrows():\n",
    "    iid = row[\"file_path\"]\n",
    "    text = row.get(\"full_text\",\"\")\n",
    "    for w in extract_words(text):\n",
    "        rows.append({\n",
    "            \"image_id\": iid,\n",
    "            \"subject_label_pl\": w.lower(),\n",
    "            \"subject_label_en\": w.lower(),\n",
    "            \"source\": \"ocr\",\n",
    "        })\n",
    "\n",
    "df_ocr = pd.DataFrame(rows).drop_duplicates()\n",
    "df_ocr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51cd1a2",
   "metadata": {},
   "source": [
    "### 5. Ścieżki plików i dane wejściowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17d4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parametry przeglądu i pliki stanu.\n",
    "\n",
    "    - PREVIEW: podglądy z ramek LVIS (jeśli istnieją), inaczej obraz źródłowy.\n",
    "    - STATE: zapis zatwierdzonych subjects per file_name (wznawialny).\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\"/Users/olga/MetaLogic\")\n",
    "P_INPUTS = ROOT / \"inputs\"\n",
    "P_PREV   = ROOT / \"outputs/lvis_try/preview\"  # miniatury z LVIS\n",
    "P_LVIS   = ROOT / \"outputs/csv/lvis_subjects_en_pl.csv\"\n",
    "P_OCR    = ROOT / \"outputs/csv/ocr_results.csv\"  # opcjonalnie do dc.description\n",
    "\n",
    "P_REVIEW = ROOT / \"outputs/review/review_subjects.csv\"\n",
    "P_REVIEW.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_csv_safe(p: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(p) if p.exists() else pd.DataFrame()\n",
    "\n",
    "df_lvis = read_csv_safe(P_LVIS)\n",
    "df_ocr  = read_csv_safe(P_OCR)\n",
    "\n",
    "if P_REVIEW.exists():\n",
    "    df_review = pd.read_csv(P_REVIEW)\n",
    "else:\n",
    "    df_review = pd.DataFrame(\n",
    "        columns=[\"file_name\", \"subjects_pl\", \"subjects_en\", \"notes\", \"reviewed\"]\n",
    "    )\n",
    "\n",
    "inputs_all = sorted([\n",
    "    p.name for p in P_INPUTS.iterdir()\n",
    "    if p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20e07b",
   "metadata": {},
   "source": [
    "### 6. Proponowane subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa4aaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kandydaci subjects per-obraz:\n",
    "- LVIS: unikalne etykiety EN/PL dla danego pliku (max topk).\n",
    "- CLIP: sceny EN/PL (jeśli są).\n",
    "- Słownik globalny PL (VOCAB_PL) dodawany tylko, gdy włączysz przełącznik w UI.\n",
    "\"\"\"\n",
    "\n",
    "LVIS_TOP_DEFAULT = 12\n",
    "\n",
    "def _split_semis(s: str):\n",
    "    return [t.strip() for t in str(s or \"\").split(\";\") if t and t.strip()]\n",
    "\n",
    "def _vocab_pl_from_data():\n",
    "    \"\"\"\n",
    "    Buduje słownik PL z dotychczasowych recenzji (df_review).\n",
    "    Służy jako dodatkowa lista propozycji, gdy w UI zaznaczysz add_vocab_pl.\n",
    "    \"\"\"\n",
    "    pool = []\n",
    "    if not df_review.empty and \"subjects_pl\" in df_review.columns:\n",
    "        for s in df_review[\"subjects_pl\"].dropna().astype(str):\n",
    "            pool += _split_semis(s)\n",
    "\n",
    "    seen, out = set(), []\n",
    "    for w in pool:\n",
    "        k = w.lower()\n",
    "        if k not in seen:\n",
    "            seen.add(k)\n",
    "            out.append(w)\n",
    "    return out\n",
    "\n",
    "VOCAB_PL = _vocab_pl_from_data()\n",
    "\n",
    "def candidates_for(fname: str, topk: int = LVIS_TOP_DEFAULT, add_vocab_pl: bool = False):\n",
    "    cand_pl, cand_en = [], []\n",
    "\n",
    "    # LVIS – korzystamy z pliku lvis_subjects_en_pl.csv\n",
    "    if not df_lvis.empty:\n",
    "        d = df_lvis[df_lvis[\"file_name\"] == fname]\n",
    "        if not d.empty:\n",
    "            en_list = (\n",
    "                d[\"subject_en\"]\n",
    "                .dropna()\n",
    "                .astype(str)\n",
    "                .tolist()\n",
    "            )\n",
    "            pl_list = (\n",
    "                d[\"subject_pl\"]\n",
    "                .dropna()\n",
    "                .astype(str)\n",
    "                .tolist()\n",
    "            )\n",
    "\n",
    "            # ograniczenie do topk unikalnych\n",
    "            def _unique(seq):\n",
    "                seen, out = set(), []\n",
    "                for x in seq:\n",
    "                    k = x.lower()\n",
    "                    if k not in seen:\n",
    "                        seen.add(k)\n",
    "                        out.append(x)\n",
    "                return out\n",
    "\n",
    "            en_list = _unique(en_list)[: int(topk)]\n",
    "            pl_list = _unique(pl_list)[: int(topk)]\n",
    "\n",
    "            cand_en += en_list\n",
    "            cand_pl += pl_list\n",
    "\n",
    "    # CLIP – sceny EN/PL (jeśli df_clip istnieje)\n",
    "    if \"df_clip\" in globals() and df_clip is not None and not df_clip.empty:\n",
    "        d = df_clip[df_clip[\"file_name\"] == fname]\n",
    "        if not d.empty:\n",
    "            cand_en += [\n",
    "                str(x) for x in d[\"subject_en\"].dropna().astype(str).tolist()\n",
    "            ]\n",
    "            cand_pl += [\n",
    "                str(x) for x in d[\"subject_pl\"].dropna().astype(str).tolist()\n",
    "            ]\n",
    "\n",
    "    # dodatkowy słownik PL (z recenzji) – opcjonalnie\n",
    "    if add_vocab_pl:\n",
    "        cand_pl += VOCAB_PL\n",
    "\n",
    "    # deduplikacja\n",
    "    def dedup(seq):\n",
    "        seen, out = set(), []\n",
    "        for x in [s for s in seq if s]:\n",
    "            k = x.lower()\n",
    "            if k not in seen:\n",
    "                seen.add(k)\n",
    "                out.append(x)\n",
    "        return out\n",
    "\n",
    "    return dedup(cand_pl), dedup(cand_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a634a2f",
   "metadata": {},
   "source": [
    "### 7. Normalizacja klucza i porządkowanie kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb7d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[norm] df_lvis  : ['file_name', 'subject_en', 'subject_pl']\n",
      "[norm] df_clip  : ['file_name', 'subject_en', 'subject_pl']\n",
      "[norm] df_ocr   : ['file_path', 'n_lines', 'total_chars', 'full_text', 'has_text']\n"
     ]
    }
   ],
   "source": [
    "### 7. Normalizacja klucza i porządkowanie kolumn (LVIS/CLIP/OCR)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def _normalize_subject_df(df: pd.DataFrame | None) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Ujednolica format ramek z propozycjami subjectów.\n",
    "\n",
    "    Docelowo:\n",
    "    - kolumna 'file_name' (tylko nazwa pliku),\n",
    "    - kolumny 'subject_en' i 'subject_pl' (jeśli brak – pusty string),\n",
    "    - 'file_name' jako pierwsza kolumna.\n",
    "\n",
    "    Jeśli ramka nie ma kolumny identyfikującej plik (file_name/image_id/image),\n",
    "    zostawiamy ją bez zmian.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # źródło identyfikatora pliku\n",
    "    if \"file_name\" in df.columns:\n",
    "        key_col = \"file_name\"\n",
    "    elif \"image_id\" in df.columns:\n",
    "        key_col = \"image_id\"\n",
    "    elif \"image\" in df.columns:\n",
    "        key_col = \"image\"\n",
    "    else:\n",
    "        # brak kolumny identyfikującej plik – nic nie zmieniamy\n",
    "        return df\n",
    "\n",
    "    # standaryzacja file_name (bez ścieżek)\n",
    "    df[\"file_name\"] = df[key_col].astype(str).map(lambda x: Path(x).name)\n",
    "\n",
    "    # upewniamy się, że są subject_en / subject_pl\n",
    "    for col in (\"subject_en\", \"subject_pl\"):\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    # kolejność kolumn: file_name, subject_en, subject_pl, reszta\n",
    "    cols = [\"file_name\", \"subject_en\", \"subject_pl\"]\n",
    "    other = [c for c in df.columns if c not in cols]\n",
    "    df = df[cols + other]\n",
    "\n",
    "    df[\"file_name\"] = df[\"file_name\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def _cols_or_none(df: pd.DataFrame | None):\n",
    "    return list(df.columns) if df is not None else None\n",
    "\n",
    "# zakładamy, że df_lvis, df_clip, df_ocr są już zdefiniowane\n",
    "df_lvis = _normalize_subject_df(df_lvis)\n",
    "df_clip = _normalize_subject_df(df_clip)\n",
    "df_ocr  = _normalize_subject_df(df_ocr)\n",
    "\n",
    "print(\"[norm] df_lvis  :\", _cols_or_none(df_lvis))\n",
    "print(\"[norm] df_clip  :\", _cols_or_none(df_clip))\n",
    "print(\"[norm] df_ocr   :\", _cols_or_none(df_ocr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf459277",
   "metadata": {},
   "source": [
    "### 8. Kandydaci subjectów (LVIS + CLIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d685ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "8. Kandydaci subjects per-obraz:\n",
    "- LVIS: unikalne etykiety EN/PL dla danego pliku (max topk, z progiem score≥conf jeśli kolumna 'score' istnieje).\n",
    "- CLIP: sceny EN/PL (jeśli są).\n",
    "\"\"\"\n",
    "\n",
    "LVIS_TOP_DEFAULT = 12\n",
    "\n",
    "def _split_semis(s: str):\n",
    "    return [t.strip() for t in str(s or \"\").split(\";\") if t and t.strip()]\n",
    "\n",
    "def candidates_for(\n",
    "    fname: str,\n",
    "    conf: float = 0.45,\n",
    "    topk: int = LVIS_TOP_DEFAULT,\n",
    "):\n",
    "    cand_pl, cand_en = [], []\n",
    "\n",
    "    # LVIS – korzystamy z pliku lvis_subjects_en_pl.csv\n",
    "    if not df_lvis.empty:\n",
    "        d = df_lvis[df_lvis[\"file_name\"] == fname]\n",
    "\n",
    "        # jeśli mamy kolumnę score, filtruj po progu conf\n",
    "        if \"score\" in d.columns:\n",
    "            d = d[d[\"score\"] >= conf]\n",
    "\n",
    "        if not d.empty:\n",
    "            en_list = (\n",
    "                d[\"subject_en\"]\n",
    "                .dropna()\n",
    "                .astype(str)\n",
    "                .tolist()\n",
    "            )\n",
    "            pl_list = (\n",
    "                d[\"subject_pl\"]\n",
    "                .dropna()\n",
    "                .astype(str)\n",
    "                .tolist()\n",
    "            )\n",
    "\n",
    "            # ograniczenie do topk unikalnych\n",
    "            def _unique(seq):\n",
    "                seen, out = set(), []\n",
    "                for x in seq:\n",
    "                    k = x.lower()\n",
    "                    if k not in seen:\n",
    "                        seen.add(k)\n",
    "                        out.append(x)\n",
    "                return out\n",
    "\n",
    "            en_list = _unique(en_list)[: int(topk)]\n",
    "            pl_list = _unique(pl_list)[: int(topk)]\n",
    "\n",
    "            cand_en += en_list\n",
    "            cand_pl += pl_list\n",
    "\n",
    "    # CLIP – sceny EN/PL (jeśli df_clip istnieje)\n",
    "    if \"df_clip\" in globals() and df_clip is not None and not df_clip.empty:\n",
    "        d = df_clip[df_clip[\"file_name\"] == fname]\n",
    "        if not d.empty:\n",
    "            cand_en += [\n",
    "                str(x) for x in d[\"subject_en\"].dropna().astype(str).tolist()\n",
    "            ]\n",
    "            cand_pl += [\n",
    "                str(x) for x in d[\"subject_pl\"].dropna().astype(str).tolist()\n",
    "            ]\n",
    "\n",
    "    # deduplikacja\n",
    "    def dedup(seq):\n",
    "        seen, out = set(), []\n",
    "        for x in [s for s in seq if s]:\n",
    "            k = x.lower()\n",
    "            if k not in seen:\n",
    "                seen.add(k)\n",
    "                out.append(x)\n",
    "        return out\n",
    "\n",
    "    return dedup(cand_pl), dedup(cand_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ce4fa",
   "metadata": {},
   "source": [
    "### 9. Wybór i zatwierdzenie subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82490c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9ea9036d004e56b977addef989b13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='◀︎ Poprzedni', layout=Layout(width='120px'), style=ButtonSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 9. Interfejs wyboru subjectów (LVIS + CLIP + OCR → subject_human_selected.csv)\n",
    "\n",
    "\"\"\"\n",
    "Dla każdego file_name pokazuje:\n",
    "- miniaturę obrazu (z P_PREV lub P_INPUTS),\n",
    "- listę subjectów (PL/EN) z df_dc_subjects jako checkboksy,\n",
    "- pole tekstowe na własne subjecty PL (oddzielone średnikami ';'),\n",
    "- pole tekstowe na tekst z OCR (oddzielony średnikami ';'),\n",
    "- checkbox + pole tekstowe na scenę (03_clip), zapisywaną w kolumnie 'universal'.\n",
    "\n",
    "Po kliknięciu „Zapisz”:\n",
    "- subjecty + ewentualne napisy z OCR trafiają do subject_human_selected.csv.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import ipywidgets as W\n",
    "from PIL import Image\n",
    "import io, base64\n",
    "\n",
    "# Bezpieczne wczytanie df_dc_subjects z pliku, jeśli nie istnieje w pamięci\n",
    "if \"df_dc_subjects\" not in globals():\n",
    "    P_DC_SUBJ = ROOT / \"outputs\" / \"csv\" / \"dc_subjects_clip_lvis.csv\"\n",
    "    if not P_DC_SUBJ.exists():\n",
    "        raise FileNotFoundError(f\"Brak pliku z subjectami DC: {P_DC_SUBJ}\")\n",
    "    df_dc_subjects = pd.read_csv(P_DC_SUBJ)\n",
    "    \n",
    "P_SUBJ_SEL = ROOT / \"outputs\" / \"csv\" / \"subject_human_selected.csv\"\n",
    "P_SUBJ_SEL.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# wczytaj istniejący wybór, jeśli jest\n",
    "if P_SUBJ_SEL.exists():\n",
    "    df_sel = pd.read_csv(P_SUBJ_SEL)\n",
    "else:\n",
    "    df_sel = pd.DataFrame(columns=[\"file_name\", \"pl\", \"en\", \"universal\", \"selected\"])\n",
    "\n",
    "# lista plików do przeglądu\n",
    "file_list = sorted(df_dc_subjects[\"file_name\"].astype(str).unique().tolist())\n",
    "idx = 0 if file_list else -1\n",
    "\n",
    "w_prev = W.Button(description=\"◀︎ Poprzedni\", layout=W.Layout(width=\"120px\"))\n",
    "w_next = W.Button(description=\"Następny ▶︎\", layout=W.Layout(width=\"120px\"))\n",
    "w_save = W.Button(description=\"Zapisz\", button_style=\"success\", layout=W.Layout(width=\"120px\"))\n",
    "w_info = W.HTML()\n",
    "\n",
    "w_img = W.HTML()   # miniatura\n",
    "w_box = W.VBox()   # checkboksy\n",
    "\n",
    "w_manual_pl = W.Textarea(\n",
    "    placeholder=\"Dodatkowe subjecty po polsku, oddzielone średnikami ';'\\nnp. pochód 1 maja; ćwikła; mleko w proszku\",\n",
    "    layout=W.Layout(width=\"100%\", height=\"70px\")\n",
    ")\n",
    "\n",
    "# tekst z OCR\n",
    "w_ocr = W.Textarea(\n",
    "    placeholder=\"Tekst z OCR (np. z transparentów), oddzielony średnikami ';'\",\n",
    "    layout=W.Layout(width=\"100%\", height=\"160px\")\n",
    ")\n",
    "w_ocr_chk = W.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Dodać tekst z OCR jako subject (PL)\",\n",
    "    indent=False,\n",
    "    layout=W.Layout(width=\"260px\"),\n",
    ")\n",
    "\n",
    "# scena CLIP (universal)\n",
    "w_scene_chk = W.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Kolumna universal\",\n",
    "    indent=False,\n",
    "    layout=W.Layout(width=\"200px\")\n",
    ")\n",
    "w_scene_text = W.Text(\n",
    "    placeholder=\"np. wnętrze sklepu\",\n",
    "    layout=W.Layout(width=\"100%\")\n",
    ")\n",
    "\n",
    "\n",
    "def _row_selected(fname: str, pl: str, en: str, universal: str) -> bool:\n",
    "    if df_sel.empty:\n",
    "        return False\n",
    "    m = (\n",
    "        (df_sel[\"file_name\"].astype(str) == fname)\n",
    "        & (df_sel[\"pl\"].astype(str) == pl)\n",
    "        & (df_sel[\"en\"].astype(str) == en)\n",
    "        & (df_sel[\"universal\"].astype(str) == universal)\n",
    "        & (df_sel[\"selected\"] == 1)\n",
    "    )\n",
    "    return bool(m.any())\n",
    "\n",
    "\n",
    "def _get_saved_scene(fname: str):\n",
    "    \"\"\"Zwraca (universal, selected) dla zapisanej sceny, jeśli istnieje.\"\"\"\n",
    "    if df_sel.empty:\n",
    "        return \"\", False\n",
    "    m = (\n",
    "        (df_sel[\"file_name\"].astype(str) == fname)\n",
    "        & (df_sel[\"pl\"].astype(str) == \"\")\n",
    "        & (df_sel[\"en\"].astype(str) == \"\")\n",
    "        & (df_sel[\"universal\"].astype(str) != \"\")\n",
    "    )\n",
    "    if not m.any():\n",
    "        return \"\", False\n",
    "    row = df_sel[m].iloc[0]\n",
    "    return str(row[\"universal\"]), bool(row.get(\"selected\", 1) == 1)\n",
    "\n",
    "\n",
    "def _get_ocr_text(fname: str) -> str:\n",
    "    \"\"\"\n",
    "    Zwraca tekst OCR dla danego pliku jako 'frag1; frag2; ...'\n",
    "    na podstawie df_ocr (ocr_results.csv z kolumnami file_name, full_text).\n",
    "    \"\"\"\n",
    "    if \"df_ocr\" not in globals() or df_ocr is None or df_ocr.empty:\n",
    "        return \"\"\n",
    "    if \"file_name\" not in df_ocr.columns or \"full_text\" not in df_ocr.columns:\n",
    "        return \"\"\n",
    "    d = df_ocr[df_ocr[\"file_name\"].astype(str) == fname]\n",
    "    if d.empty:\n",
    "        return \"\"\n",
    "\n",
    "    text = str(d[\"full_text\"].iloc[0])\n",
    "    # rozbicie na linie → frazy\n",
    "    parts = [s.strip() for s in text.replace(\"\\r\", \"\\n\").split(\"\\n\") if s.strip()]\n",
    "    if not parts:\n",
    "        return text.strip()\n",
    "\n",
    "    # deduplikacja\n",
    "    seen, out = set(), []\n",
    "    for t in parts:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out.append(t)\n",
    "    return \"; \".join(out)\n",
    "\n",
    "\n",
    "def _load_preview(fname: str) -> Image.Image:\n",
    "    cand = [P_PREV / fname, P_INPUTS / fname]\n",
    "    for p in cand:\n",
    "        if p.exists():\n",
    "            return Image.open(p).convert(\"RGB\")\n",
    "    raise FileNotFoundError(fname)\n",
    "\n",
    "\n",
    "def _pil_to_dataurl(im: Image.Image, maxw: int = 800) -> str:\n",
    "    w, h = im.size\n",
    "    if w > maxw:\n",
    "        im = im.resize((maxw, int(h * maxw / w)))\n",
    "    buf = io.BytesIO()\n",
    "    im.save(buf, format=\"JPEG\", quality=92)\n",
    "    b64 = base64.b64encode(buf.getvalue()).decode(\"ascii\")\n",
    "    return f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "\n",
    "def render_subjects():\n",
    "    w_box.children = ()\n",
    "    w_manual_pl.value = \"\"\n",
    "    w_ocr.value = \"\"\n",
    "    w_ocr_chk.value = False\n",
    "    w_scene_chk.value = False\n",
    "    w_scene_text.value = \"\"\n",
    "\n",
    "    if idx < 0 or idx >= len(file_list):\n",
    "        w_info.value = \"<b>Brak plików.</b>\"\n",
    "        w_img.value = \"\"\n",
    "        return\n",
    "\n",
    "    fname = file_list[idx]\n",
    "    rows = df_dc_subjects[df_dc_subjects[\"file_name\"].astype(str) == fname].copy()\n",
    "\n",
    "    # miniatura\n",
    "    try:\n",
    "        img = _load_preview(fname)\n",
    "        dataurl = _pil_to_dataurl(img)\n",
    "        w_img.value = f\"<div style='max-width:800px'><img src='{dataurl}' style='width:100%'/></div>\"\n",
    "    except FileNotFoundError:\n",
    "        w_img.value = \"<i>Brak podglądu.</i>\"\n",
    "\n",
    "    # checkboksy subjectów\n",
    "    checks = []\n",
    "    for _, r in rows.iterrows():\n",
    "        pl = str(r[\"pl\"])\n",
    "        en = str(r[\"en\"])\n",
    "        uni = str(r.get(\"universal\", \"\"))\n",
    "\n",
    "        label = pl if pl else en if en else uni\n",
    "        if pl and en:\n",
    "            label = f\"{pl} / {en}\"\n",
    "\n",
    "        chk = W.Checkbox(\n",
    "            value=_row_selected(fname, pl, en, uni),\n",
    "            description=label,\n",
    "            indent=False,\n",
    "        )\n",
    "        chk._meta = {\n",
    "            \"file_name\": fname,\n",
    "            \"pl\": pl,\n",
    "            \"en\": en,\n",
    "            \"universal\": uni,\n",
    "        }\n",
    "        checks.append(chk)\n",
    "\n",
    "    if not checks:\n",
    "        checks.append(W.HTML(\"<i>Brak subjectów dla tego pliku.</i>\"))\n",
    "\n",
    "    w_box.children = tuple(checks)\n",
    "\n",
    "    # scena CLIP – najpierw PL, potem EN\n",
    "    saved_uni, saved_sel = _get_saved_scene(fname)\n",
    "    scene_suggest = \"\"\n",
    "\n",
    "    if (\n",
    "        not saved_uni\n",
    "        and \"df_clip\" in globals()\n",
    "        and df_clip is not None\n",
    "        and not df_clip.empty\n",
    "    ):\n",
    "        d_clip = df_clip[df_clip[\"file_name\"].astype(str) == fname]\n",
    "        if not d_clip.empty:\n",
    "            if \"subject_pl\" in d_clip.columns and pd.notna(d_clip[\"subject_pl\"].iloc[0]):\n",
    "                scene_suggest = str(d_clip[\"subject_pl\"].iloc[0])\n",
    "            elif \"subject_en\" in d_clip.columns and pd.notna(d_clip[\"subject_en\"].iloc[0]):\n",
    "                scene_suggest = str(d_clip[\"subject_en\"].iloc[0])\n",
    "\n",
    "    if saved_uni:\n",
    "        w_scene_text.value = saved_uni\n",
    "        w_scene_chk.value = saved_sel\n",
    "    else:\n",
    "        w_scene_text.value = scene_suggest\n",
    "        w_scene_chk.value = False\n",
    "\n",
    "    # tekst z OCR – propozycja z df_ocr dla danego file_name\n",
    "    w_ocr.value = _get_ocr_text(fname)\n",
    "\n",
    "    w_info.value = f\"<b>{fname}</b> &nbsp;({idx+1} / {len(file_list)})\"\n",
    "\n",
    "\n",
    "def on_prev(_):\n",
    "    global idx\n",
    "    if idx > 0:\n",
    "        idx -= 1\n",
    "        render_subjects()\n",
    "\n",
    "\n",
    "def on_next(_):\n",
    "    global idx\n",
    "    if idx < len(file_list) - 1:\n",
    "        idx += 1\n",
    "        render_subjects()\n",
    "\n",
    "\n",
    "def on_save(_):\n",
    "    global df_sel\n",
    "    if idx < 0 or idx >= len(file_list):\n",
    "        return\n",
    "\n",
    "    fname = file_list[idx]\n",
    "    rows = []\n",
    "\n",
    "    # 1) wiersze z checkboxów (LVIS/CLIP subjects)\n",
    "    for w in w_box.children:\n",
    "        if not isinstance(w, W.Checkbox):\n",
    "            continue\n",
    "        meta = getattr(w, \"_meta\", None)\n",
    "        if meta is None:\n",
    "            continue\n",
    "        row = {\n",
    "            \"file_name\": meta[\"file_name\"],\n",
    "            \"pl\": meta[\"pl\"],\n",
    "            \"en\": meta[\"en\"],\n",
    "            \"universal\": meta[\"universal\"],\n",
    "            \"selected\": 1 if w.value else 0,\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    # 2) dodatkowe subjecty PL wpisane ręcznie\n",
    "    extra = [\n",
    "        t.strip() for t in w_manual_pl.value.split(\";\")\n",
    "        if t and t.strip()\n",
    "    ]\n",
    "    for pl in extra:\n",
    "        rows.append({\n",
    "            \"file_name\": fname,\n",
    "            \"pl\": pl,\n",
    "            \"en\": \"\",\n",
    "            \"universal\": \"\",\n",
    "            \"selected\": 1,\n",
    "        })\n",
    "\n",
    "    # 3) tekst z OCR → opcjonalnie jako subjecty PL\n",
    "    ocr_text = w_ocr.value.strip()\n",
    "    if w_ocr_chk.value and ocr_text:\n",
    "        for pl in [t.strip() for t in ocr_text.split(\";\") if t.strip()]:\n",
    "            rows.append({\n",
    "                \"file_name\": fname,\n",
    "                \"pl\": pl,\n",
    "                \"en\": \"\",\n",
    "                \"universal\": \"\",\n",
    "                \"selected\": 1,\n",
    "            })\n",
    "\n",
    "    # 4) scena CLIP / ręczna → universal\n",
    "    scene_text = w_scene_text.value.strip()\n",
    "    if w_scene_chk.value and scene_text:\n",
    "        rows.append({\n",
    "            \"file_name\": fname,\n",
    "            \"pl\": \"\",\n",
    "            \"en\": \"\",\n",
    "            \"universal\": scene_text,\n",
    "            \"selected\": 1,\n",
    "        })\n",
    "\n",
    "    df_new = pd.DataFrame(rows)\n",
    "\n",
    "    # usuń stare wpisy dla tego file_name i wstaw nowe\n",
    "    df_sel = df_sel[df_sel[\"file_name\"].astype(str) != fname]\n",
    "    df_sel = pd.concat([df_sel, df_new], ignore_index=True)\n",
    "\n",
    "    df_sel.to_csv(P_SUBJ_SEL, index=False)\n",
    "    print(f\"[DC] Zapisano wybory dla {fname} do:\", P_SUBJ_SEL)\n",
    "\n",
    "    on_next(None)\n",
    "\n",
    "\n",
    "w_prev.on_click(on_prev)\n",
    "w_next.on_click(on_next)\n",
    "w_save.on_click(on_save)\n",
    "\n",
    "controls = W.HBox([w_prev, w_next, w_save, w_info])\n",
    "ui = W.VBox([\n",
    "    controls,\n",
    "    W.HBox([\n",
    "        w_img,\n",
    "        W.VBox([\n",
    "            w_box,\n",
    "            w_manual_pl,\n",
    "            w_ocr,\n",
    "            w_ocr_chk,\n",
    "            W.HBox([w_scene_chk, w_scene_text]),\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "render_subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a2365",
   "metadata": {},
   "source": [
    "### 10. Scalanie df_dc_subjects z subject_human_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a70f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DC] Zapisano finalny eksport DC do: /Users/olga/MetaLogic/outputs/csv/dublin_core_subjects_final.csv\n",
      "[DC] df_final shape: (31, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>pl</th>\n",
       "      <th>en</th>\n",
       "      <th>universal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0077.jpg</td>\n",
       "      <td>szyld</td>\n",
       "      <td>signboard</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0077.jpg</td>\n",
       "      <td>słup telefoniczny</td>\n",
       "      <td>telephone_pole</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0077.jpg</td>\n",
       "      <td>tłum na ulicy</td>\n",
       "      <td>crowd of people on the street</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0077.jpg</td>\n",
       "      <td>kalinowka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>butelka wina</td>\n",
       "      <td>wine_bottle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>etykieta</td>\n",
       "      <td>tag</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>ćwikła</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>dżem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>UWAGA!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>Sprzedaż mleka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>pelnotłustego w proszku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>tylko za okazaniem aktualnej</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>książeczki zdrowia dziecka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wnętrze sklepu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>spódnica</td>\n",
       "      <td>skirt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>markiza</td>\n",
       "      <td>awning</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>tłum na ulicy</td>\n",
       "      <td>crowd of people on the street</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>35 lat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>ZTL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0006.jpg</td>\n",
       "      <td>UMCS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name                            pl                             en  \\\n",
       "8   0077.jpg                         szyld                      signboard   \n",
       "10  0077.jpg             słup telefoniczny                 telephone_pole   \n",
       "11  0077.jpg                 tłum na ulicy  crowd of people on the street   \n",
       "12  0077.jpg                     kalinowka                            NaN   \n",
       "14  0004.jpg                  butelka wina                    wine_bottle   \n",
       "15  0004.jpg                      etykieta                            tag   \n",
       "19  0004.jpg                        ćwikła                            NaN   \n",
       "20  0004.jpg                          dżem                            NaN   \n",
       "21  0004.jpg                        UWAGA!                            NaN   \n",
       "22  0004.jpg                Sprzedaż mleka                            NaN   \n",
       "23  0004.jpg       pelnotłustego w proszku                            NaN   \n",
       "24  0004.jpg  tylko za okazaniem aktualnej                            NaN   \n",
       "25  0004.jpg    książeczki zdrowia dziecka                            NaN   \n",
       "26  0004.jpg                           NaN                            NaN   \n",
       "27  0006.jpg                      spódnica                          skirt   \n",
       "31  0006.jpg                       markiza                         awning   \n",
       "37  0006.jpg                 tłum na ulicy  crowd of people on the street   \n",
       "38  0006.jpg                        35 lat                            NaN   \n",
       "39  0006.jpg                           ZTL                            NaN   \n",
       "40  0006.jpg                          UMCS                            NaN   \n",
       "\n",
       "         universal  \n",
       "8              NaN  \n",
       "10             NaN  \n",
       "11             NaN  \n",
       "12             NaN  \n",
       "14             NaN  \n",
       "15             NaN  \n",
       "19             NaN  \n",
       "20             NaN  \n",
       "21             NaN  \n",
       "22             NaN  \n",
       "23             NaN  \n",
       "24             NaN  \n",
       "25             NaN  \n",
       "26  wnętrze sklepu  \n",
       "27             NaN  \n",
       "31             NaN  \n",
       "37             NaN  \n",
       "38             NaN  \n",
       "39             NaN  \n",
       "40             NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 7.Z Scalanie df_dc_subjects z subject_human_selected → human_selected\n",
    "\n",
    "\"\"\"\n",
    "Tworzy finalną tabelę DC z uwzględnieniem wyborów człowieka.\n",
    "\n",
    "Zasady:\n",
    "- Jeśli subject_human_selected.csv istnieje i zawiera selected==1,\n",
    "  do eksportu trafiają tylko te wiersze.\n",
    "- Jeśli plik nie istnieje lub nie ma żadnych selected==1,\n",
    "  eksportujemy wszystkie wiersze z df_dc_subjects.\n",
    "\n",
    "Wyjście:\n",
    "    outputs/csv/dublin_core_subjects_final.csv\n",
    "    kolumny: file_name, pl, en, universal\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "P_DC_SUBJ   = ROOT / \"outputs\" / \"csv\" / \"dc_subjects_clip_lvis.csv\"\n",
    "P_SUBJ_SEL  = ROOT / \"outputs\" / \"csv\" / \"subject_human_selected.csv\"\n",
    "P_DC_FINAL  = ROOT / \"outputs\" / \"csv\" / \"dublin_core_subjects_final.csv\"\n",
    "P_DC_FINAL.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# baza: wszystkie subjecty z LVIS+CLIP (fallback)\n",
    "df_all = pd.read_csv(P_DC_SUBJ) if P_DC_SUBJ.exists() else df_dc_subjects.copy()\n",
    "\n",
    "# wybory człowieka (mogą nie istnieć)\n",
    "if P_SUBJ_SEL.exists():\n",
    "    df_sel = pd.read_csv(P_SUBJ_SEL)\n",
    "else:\n",
    "    df_sel = pd.DataFrame(columns=[\"file_name\", \"pl\", \"en\", \"universal\", \"selected\"])\n",
    "\n",
    "if (\n",
    "    not df_sel.empty\n",
    "    and \"selected\" in df_sel.columns\n",
    "    and df_sel[\"selected\"].sum() > 0\n",
    "):\n",
    "    # używamy WYŁĄCZNIE wierszy wybranych przez człowieka\n",
    "    df_final = (\n",
    "        df_sel[df_sel[\"selected\"] == 1]\n",
    "        .loc[:, [\"file_name\", \"pl\", \"en\", \"universal\"]]\n",
    "        .copy()\n",
    "    )\n",
    "else:\n",
    "    # brak zaznaczeń – bierzemy wszystko z automatu\n",
    "    df_final = df_all.loc[:, [\"file_name\", \"pl\", \"en\", \"universal\"]].copy()\n",
    "\n",
    "df_final.to_csv(P_DC_FINAL, index=False)\n",
    "print(\"[DC] Zapisano finalny eksport DC do:\", P_DC_FINAL)\n",
    "print(\"[DC] df_final shape:\", df_final.shape)\n",
    "df_final.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv MetaLogic)",
   "language": "python",
   "name": "metalogic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d90535a",
   "metadata": {},
   "source": [
    "##### Uruchamianie wszystkiego co działa na Macu:\n",
    "YOLO, LVIS, OWL-ViT, lekki DETR (jeżeli chcesz).\n",
    "Zapis w jednolitym formacie CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c3212",
   "metadata": {},
   "source": [
    "### 0. Importy, ścieżki i konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b62b8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Przygotowanie środowiska dla benchmarku detektorów uruchamianych na Macu:\n",
    "- YOLO (model własny),\n",
    "- LVIS (gotowy model),\n",
    "- OWL-ViT (open-vocabulary),\n",
    "- opcjonalnie DETR.\n",
    "\n",
    "Założenia:\n",
    "- 08_eval_setup.ipynb utworzył plik outputs/detector_eval/eval_file_list.csv\n",
    "  z kolumną 'file_name'.\n",
    "- Obrazy testowe fizycznie znajdują się w katalogu data/test_scenes\n",
    "  względem PROJECT_ROOT.\n",
    "\"\"\"\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "IMAGES_DIR = DATA_DIR / \"test_scenes\"\n",
    "\n",
    "EVAL_OUTPUT_DIR = PROJECT_ROOT / \"outputs\" / \"detector_eval\"\n",
    "EVAL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_LIST_CSV = EVAL_OUTPUT_DIR / \"eval_file_list.csv\"\n",
    "df_files = pd.read_csv(TEST_LIST_CSV)\n",
    "file_list: List[str] = df_files[\"file_name\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce17588",
   "metadata": {},
   "source": [
    "### 1. Wspólna funkcja pomocnicza: format wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "352c0da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definiuje funkcję pomocniczą tworzącą pusty DataFrame w jednolitym formacie.\n",
    "\n",
    "Kolumny:\n",
    "- file_name, model, prompt, class_raw, class_norm, score,\n",
    "- x_min, y_min, x_max, y_max.\n",
    "\"\"\"\n",
    "\n",
    "DETECTIONS_COLUMNS = [\n",
    "    \"file_name\",\n",
    "    \"model\",\n",
    "    \"prompt\",\n",
    "    \"class_raw\",\n",
    "    \"class_norm\",\n",
    "    \"score\",\n",
    "    \"x_min\",\n",
    "    \"y_min\",\n",
    "    \"x_max\",\n",
    "    \"y_max\",\n",
    "]\n",
    "\n",
    "\n",
    "def empty_detections_df() -> pd.DataFrame:\n",
    "    \"\"\"Zwraca pusty DataFrame z kolumnami DETECTIONS_COLUMNS.\"\"\"\n",
    "    return pd.DataFrame(columns=DETECTIONS_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be18c1",
   "metadata": {},
   "source": [
    "### 2. Funkcja run_yolo (szkielet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c5a07992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\"\"\"\n",
    "YOLO – model trenowany na Syrenę i Malucha.\n",
    "\"\"\"\n",
    "\n",
    "BEST_RUN = \"syrena_maluch_fast2\"  # <- tu wstaw wybrany run\n",
    "YOLO_MODEL_PATH = PROJECT_ROOT / \"outputs\" / \"yolo_cars\" / BEST_RUN / \"weights\" / \"best.pt\"\n",
    "\n",
    "# indeksy klas w Twoim modelu YOLO\n",
    "YOLO_IDX_TO_CLASS_NORM = {\n",
    "    0: \"maluch\",\n",
    "    1: \"syrena\",\n",
    "}\n",
    "\n",
    "\n",
    "def run_yolo(file_names: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uruchamia model YOLO (Syrena/Maluch) na liście plików.\n",
    "\n",
    "    file_names – lista nazw plików (bez ścieżek).\n",
    "    Zwraca DataFrame z kolumnami DETECTIONS_COLUMNS.\n",
    "\n",
    "    Założenia:\n",
    "    - obrazy znajdują się w katalogu IMAGES_DIR,\n",
    "    - YOLO_MODEL_PATH wskazuje na best.pt z treningu Syrena/Maluch.\n",
    "    \"\"\"\n",
    "\n",
    "    model = YOLO(str(YOLO_MODEL_PATH))\n",
    "    rows = []\n",
    "\n",
    "    for fname in file_names:\n",
    "        img_path = IMAGES_DIR / fname\n",
    "        if not img_path.exists():\n",
    "            continue\n",
    "\n",
    "        results = model(source=str(img_path), verbose=False)\n",
    "\n",
    "        for r in results:\n",
    "            if r.boxes is None:\n",
    "                continue\n",
    "\n",
    "            for box in r.boxes:\n",
    "                cls_idx = int(box.cls.item())\n",
    "                score = float(box.conf.item())\n",
    "                xyxy = box.xyxy[0].tolist()  # [x1, y1, x2, y2]\n",
    "\n",
    "                class_norm = YOLO_IDX_TO_CLASS_NORM.get(cls_idx, None)\n",
    "                class_raw = model.names.get(cls_idx, str(cls_idx))\n",
    "\n",
    "                rows.append(\n",
    "                    {\n",
    "                        \"file_name\": fname,\n",
    "                        \"model\": \"yolo_syrena_maluch\",\n",
    "                        \"prompt\": \"\",\n",
    "                        \"class_raw\": class_raw,\n",
    "                        \"class_norm\": class_norm,\n",
    "                        \"score\": score,\n",
    "                        \"x_min\": xyxy[0],\n",
    "                        \"y_min\": xyxy[1],\n",
    "                        \"x_max\": xyxy[2],\n",
    "                        \"y_max\": xyxy[3],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if not rows:\n",
    "        return empty_detections_df()\n",
    "\n",
    "    return pd.DataFrame(rows, columns=DETECTIONS_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c66af",
   "metadata": {},
   "source": [
    "### Konfiguracja LVIS dla benchmarku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c3fd227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\"\"\"\n",
    "Konfiguracja LVIS dla benchmarku.\n",
    "\n",
    "Wykorzystujemy słownik:\n",
    "- outputs/csv/lvis_subjects_en_pl.csv\n",
    "\n",
    "Struktura oczekiwana:\n",
    "- file_name   – nazwa pliku (może być pełna ścieżka),\n",
    "- subject_en  – etykieta LVIS (np. 'car_(automobile)', 'dog', 'street_sign'),\n",
    "- subject_pl  – tłumaczenie na polski (tu nie jest używane w benchmarku detektorów).\n",
    "\n",
    "UWAGA:\n",
    "- brak bboxów i score → LVIS traktujemy jako „tagger obrazów”.\n",
    "\"\"\"\n",
    "\n",
    "LVIS_RAW_CSV = PROJECT_ROOT / \"outputs\" / \"csv\" / \"lvis_subjects_en_pl.csv\"\n",
    "\n",
    "if not LVIS_RAW_CSV.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Nie znaleziono pliku z wynikami LVIS: {LVIS_RAW_CSV.as_posix()}\\n\"\n",
    "        \"Sprawdź, czy ścieżka jest poprawna.\"\n",
    "    )\n",
    "\n",
    "df_lvis_raw = pd.read_csv(LVIS_RAW_CSV)\n",
    "\n",
    "required_cols = {\"file_name\", \"subject_en\", \"subject_pl\"}\n",
    "missing = required_cols - set(df_lvis_raw.columns)\n",
    "if missing:\n",
    "    raise ValueError(\n",
    "        f\"Brakuje kolumn w df_lvis_raw: {missing}\\n\"\n",
    "        \"Sprawdź strukturę pliku lvis_subjects_en_pl.csv.\"\n",
    "    )\n",
    "\n",
    "# normalizacja nazw plików: zawsze bierzemy samą nazwę (bez ścieżki)\n",
    "df_lvis_raw[\"file_name_norm\"] = df_lvis_raw[\"file_name\"].apply(\n",
    "    lambda x: Path(str(x)).name\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Mapowanie etykiet LVIS (subject_en) → Twoje class_norm.\n",
    "\n",
    "Na razie przykładowe mapowania – rozszerzysz po obejrzeniu unikalnych subject_en.\n",
    "\"\"\"\n",
    "\n",
    "LVIS_LABEL_TO_CLASS_NORM = {\n",
    "    # pojazdy\n",
    "    \"car_(automobile)\": \"samochod_inny\",\n",
    "    \"freight_car\": \"samochod_inny\",\n",
    "    \"bus_(vehicle)\": \"autobus\",\n",
    "\n",
    "    # zwierzęta\n",
    "    \"dog\": \"pies\",\n",
    "    # \"domestic_cat\": \"kot\",  # dopisz jeśli występuje\n",
    "\n",
    "    # znaki / szyldy\n",
    "    \"traffic_light\": \"znak_drogowy\",\n",
    "    \"stop_sign\": \"znak_drogowy\",\n",
    "    \"street_sign\": \"znak_drogowy\",\n",
    "    \"store_sign\": \"szyld_sklepowy\",\n",
    "    \"shop_sign\": \"szyld_sklepowy\",\n",
    "\n",
    "    # architektura – do uzupełnienia po obejrzeniu danych\n",
    "    # \"church\": \"kosciol\",\n",
    "    # \"tower\": \"zabytkowa_wieza\",\n",
    "    # \"balcony\": \"balkon\",\n",
    "    # \"shop_window\": \"witryna_sklepowa\",\n",
    "    # \"store_window\": \"witryna_sklepowa\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe57489",
   "metadata": {},
   "source": [
    "### 3. Funkcja run_lvis (szkielet podmieniony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bb27c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lvis(file_names: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Wykorzystuje słownik LVIS (lvis_subjects_en_pl.csv) jako źródło detekcji na poziomie obrazu.\n",
    "\n",
    "    Logika:\n",
    "    - df_lvis_raw: wiersz = (file_name, subject_en, subject_pl),\n",
    "    - file_name_norm = tylko nazwa pliku (bez ścieżki),\n",
    "    - filtrujemy tylko obrazy z listy file_names,\n",
    "    - subject_en → class_raw,\n",
    "    - subject_en → class_norm (słownik LVIS_LABEL_TO_CLASS_NORM),\n",
    "    - bbox = 0.0 (placeholder), score = 1.0 (brak realnego score).\n",
    "\n",
    "    file_names – lista nazw plików (bez ścieżek).\n",
    "    \"\"\"\n",
    "\n",
    "    if df_lvis_raw.empty:\n",
    "        return empty_detections_df()\n",
    "\n",
    "    # filtr po znormalizowanej nazwie\n",
    "    df_sel = df_lvis_raw[df_lvis_raw[\"file_name_norm\"].isin(file_names)].copy()\n",
    "    if df_sel.empty:\n",
    "        return empty_detections_df()\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df_sel.iterrows():\n",
    "        fname = str(row[\"file_name_norm\"])\n",
    "        label_en = str(row[\"subject_en\"])\n",
    "\n",
    "        class_raw = label_en\n",
    "        class_norm = LVIS_LABEL_TO_CLASS_NORM.get(label_en, None)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"file_name\": fname,\n",
    "                \"model\": \"lvis\",\n",
    "                \"prompt\": \"\",          # LVIS nie używa promptów tekstowych\n",
    "                \"class_raw\": class_raw,\n",
    "                \"class_norm\": class_norm,\n",
    "                \"score\": 1.0,          # brak realnego score – stała wartość\n",
    "                \"x_min\": 0.0,\n",
    "                \"y_min\": 0.0,\n",
    "                \"x_max\": 0.0,\n",
    "                \"y_max\": 0.0,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not rows:\n",
    "        return empty_detections_df()\n",
    "\n",
    "    return pd.DataFrame(rows, columns=DETECTIONS_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65962f1",
   "metadata": {},
   "source": [
    "### 4. Funkcja run_owl_vit (szkielet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28bbb389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_owl_vit(file_names: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uruchamia model OWL-ViT (open-vocabulary) na liście plików.\n",
    "\n",
    "    file_names – lista nazw plików (bez ścieżek).\n",
    "    Zwraca DataFrame z kolumnami DETECTIONS_COLUMNS.\n",
    "\n",
    "    TODO:\n",
    "    - załadować model OWL-ViT (np. z transformers),\n",
    "    - zdefiniować listę promptów (na podstawie PROMPTS_BY_CLASS),\n",
    "    - dla każdego obrazu i promptu zebrać boxy i wyniki,\n",
    "    - zapisać prompt i class_raw (= prompt lub nazwa klasy),\n",
    "    - zmapować na class_norm.\n",
    "    \"\"\"\n",
    "    df = empty_detections_df()\n",
    "    # TODO: implementacja detekcji OWL-ViT\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667e224",
   "metadata": {},
   "source": [
    "### 5. Funkcja run_detr (opcjonalnie, szkielet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e7ea1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detr(file_names: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uruchamia wybrany model DETR na liście plików (opcjonalnie).\n",
    "\n",
    "    file_names – lista nazw plików (bez ścieżek).\n",
    "    Zwraca DataFrame z kolumnami DETECTIONS_COLUMNS.\n",
    "\n",
    "    TODO:\n",
    "    - załadować model DETR (torchvision / transformers),\n",
    "    - uruchomić detekcję na każdym obrazie,\n",
    "    - zmapować klasy na class_norm (np. car → samochod_inny).\n",
    "    \"\"\"\n",
    "    df = empty_detections_df()\n",
    "    # TODO: implementacja detekcji DETR\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "960c7e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_norm\n",
       "maluch    7\n",
       "syrena    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yolo.head()\n",
    "df_yolo[\"class_norm\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e7d1306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LVIS rows: 1072\n",
      "Unikalne file_name_norm w LVIS: 74\n",
      "Przykład: 0    0004.jpg\n",
      "1    0004.jpg\n",
      "2    0004.jpg\n",
      "3    0004.jpg\n",
      "4    0004.jpg\n",
      "Name: file_name_norm, dtype: object\n",
      "Przykład z file_list: ['0000.jpg', '000202.jpg', '000238.jpg', '0003.jpg', '000345.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(\"LVIS rows:\", len(df_lvis_raw))\n",
    "print(\"Unikalne file_name_norm w LVIS:\", df_lvis_raw[\"file_name_norm\"].nunique())\n",
    "print(\"Przykład:\", df_lvis_raw[\"file_name_norm\"].head())\n",
    "print(\"Przykład z file_list:\", file_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59f5f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wierszy: 12\n",
      "class_norm\n",
      "maluch    7\n",
      "syrena    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "EVAL_OUTPUT_DIR = PROJECT_ROOT / \"outputs\" / \"detector_eval\"\n",
    "\n",
    "df_yolo = pd.read_csv(EVAL_OUTPUT_DIR / \"detections_yolo_syrena_maluch.csv\")\n",
    "print(\"Wierszy:\", len(df_yolo))\n",
    "print(df_yolo[\"class_norm\"].value_counts(dropna=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv MetaLogic)",
   "language": "python",
   "name": "metalogic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

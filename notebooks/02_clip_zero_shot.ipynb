{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798dcd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olga/MetaLogic/.venv/lib/python3.13/site-packages/open_clip/factory.py:450: UserWarning: QuickGELU mismatch between final model config (quick_gelu=False) and pretrained tag 'openai' (quick_gelu=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT OK ‚Üí device=mps, model=ViT-B-32/openai, classes=['przed 1945', 'PRL 1945‚Äì1989', 'po 1990']\n"
     ]
    }
   ],
   "source": [
    "# INIT ‚Äî CLIP zero-shot + predict\n",
    "# Uruchom tƒô kom√≥rkƒô po restarcie kernela. Potem od razu UI.\n",
    "\n",
    "import torch, open_clip\n",
    "from PIL import Image\n",
    "\n",
    "# 1) UrzƒÖdzenie\n",
    "DEVICE = (\n",
    "    \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "# 2) Model FP16\n",
    "MODEL_NAME = \"ViT-B-32\"\n",
    "PRETRAINED = \"openai\"  # lub \"laion2b_s34b_b79k\"\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(MODEL_NAME, pretrained=PRETRAINED)\n",
    "model = model.eval().to(DEVICE)\n",
    "model.to(dtype=torch.float16)  # sp√≥jno≈õƒá FP16\n",
    "\n",
    "# 3) Klasy i prompty (najpro≈õciej: tu lokalnie)\n",
    "LABELS = [\"przed 1945\", \"PRL 1945‚Äì1989\", \"po 1990\"]\n",
    "TEXT_PROMPTS = [\n",
    "    \"photograph in Poland before 1945; interwar clothing; prewar architecture; cobblestones; horse carriages; sepia or black-and-white\",\n",
    "    \"photo from the Polish People‚Äôs Republic 1945‚Äì1989; prefab blocks; neon signs; RUCH kiosk; Fiat 126p, Polonez, ≈ªuk; 70s‚Äì80s clothing; socialist posters\",\n",
    "    \"photograph in Poland after 1990; modern ads; PVC banners; smartphones; cars after 2005; malls; glass offices; renovated tenements\",\n",
    "]\n",
    "\n",
    "# 4) Teksty ‚Üí wektory\n",
    "tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
    "with torch.no_grad():\n",
    "    text_tokens = tokenizer(TEXT_PROMPTS).to(DEVICE)\n",
    "    text_features = model.encode_text(text_tokens)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# 5) Predykcja dla obrazu PIL\n",
    "def predict(pil_img: Image.Image):\n",
    "    pil = pil_img.convert(\"RGB\")\n",
    "    image = preprocess(pil).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    # dopasuj dtype wej≈õcia do wag modelu (FP16)\n",
    "    target_dtype = next(model.parameters()).dtype\n",
    "    image = image.to(dtype=target_dtype)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        logits = (100.0 * image_features @ text_features.T).squeeze(0)\n",
    "        probs = logits.softmax(dim=-1)\n",
    "\n",
    "    scores = {LABELS[i]: float(probs[i].item()) for i in range(len(LABELS))}\n",
    "    label = LABELS[int(torch.argmax(probs).item())]\n",
    "    return scores, label\n",
    "\n",
    "print(f\"INIT OK ‚Üí device={DEVICE}, model={MODEL_NAME}/{PRETRAINED}, classes={LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19728076",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Importy i inicjalizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fd5a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Run ID: 2025-11-12T13:24:09+00:00\n"
     ]
    }
   ],
   "source": [
    "# 1Ô∏è‚É£ Importy i inicjalizacja\n",
    "\"\"\"\n",
    "Zero-shot klasyfikacja obraz√≥w (np. PRL / non-PRL) przy u≈ºyciu modelu CLIP.\n",
    "U≈ºywa FP16 dla sp√≥jno≈õci z trenowaniem i oszczƒôdno≈õci pamiƒôci.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import open_clip\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datetime import datetime, timezone\n",
    "import time, json\n",
    "\n",
    "# ≈öcie≈ºki\n",
    "DIR_STAGING = Path(\"data/staging\")\n",
    "DIR_OUT = Path(\"outputs\")\n",
    "DIR_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Detekcja urzƒÖdzenia\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Rejestracja runu\n",
    "run_id = datetime.now(timezone.utc).isoformat(timespec=\"seconds\")\n",
    "print(\"Run ID:\", run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29770f66",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ ≈Åadowanie modelu CLIP (FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff4be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olga/MetaLogic/.venv/lib/python3.13/site-packages/open_clip/factory.py:450: UserWarning: QuickGELU mismatch between final model config (quick_gelu=False) and pretrained tag 'openai' (quick_gelu=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Za≈Çadowano model: ViT-B-32\n"
     ]
    }
   ],
   "source": [
    "# 2Ô∏è‚É£ ≈Åadowanie modelu CLIP (FP16)\n",
    "\"\"\"\n",
    "≈Åaduje model CLIP (ViT-B/32) z biblioteki open_clip_torch.\n",
    "Ustawia FP16 i tryb ewaluacji.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = \"ViT-B-32\"\n",
    "PRETRAINED = \"openai\"\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    MODEL_NAME, pretrained=PRETRAINED\n",
    ")\n",
    "tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
    "\n",
    "model = model.eval().to(device)\n",
    "model.to(dtype=torch.float16)\n",
    "\n",
    "print(\"Za≈Çadowano model:\", MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2acc4c",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Definicja etykiet i pe≈Çnych prompt√≥w opisowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9482f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbudowano 3 klasy: do 1944, PRL 1945‚Äì1989, po 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/5zl19j_12ps2q88dx76v08_c0000gp/T/ipykernel_50213/2686638956.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.float16):\n",
      "/Users/olga/MetaLogic/.venv/lib/python3.13/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3Ô∏è‚É£ Definicja etykiet i pe≈Çnych prompt√≥w opisowych\n",
    "\"\"\"\n",
    "Trzy klasy epok: przed 1945, PRL (1945‚Äì1989), po 1990.\n",
    "Ka≈ºda ma bogaty prompt tekstowy opisujƒÖcy kontekst wizualny sceny.\n",
    "\"\"\"\n",
    "\n",
    "LABELS = [\"do 1944\", \"PRL 1945‚Äì1989\", \"po 1990\"]\n",
    "\n",
    "TEXT_PROMPTS = [\n",
    "    # A) Do 1944\n",
    "    \"photograph taken in Poland up to 1944; interwar or older clothing; coats, hats, uniforms; cobblestone streets; prewar tenement houses; horse carriages or very old cars; hand-painted shop signs; art deco typography; sepia or black and white style\",\n",
    "\n",
    "    # B) PRL 1945‚Äì1989\n",
    "    \"photo from the Polish People's Republic (1945‚Äì1989), PRL; prefab panel blocks, RUCH kiosk, neon signs, 'Spo≈Çem' or 'Pewex' stores; queues and everyday street scenes; 1970s‚Äì1980s clothing with shaggy hairstyles, thick-rimmed glasses, polyester suits; Fiat 126p, Polonez, ≈ªuk or Nysa vans; community theater or amateur performances; socialist-era typography and posters\",\n",
    "\n",
    "    # C) Po 1990\n",
    "    \"photograph in Poland after 1990; modern ads and global brand logos; PVC banners, colorful shop signs; street trade and open markets; modern cars after 2005; sportswear with visible logos; smartphones, glass office buildings, shopping malls, renovated tenement houses\",\n",
    "]\n",
    "\n",
    "print(f\"Zbudowano {len(LABELS)} klasy: {', '.join(LABELS)}\")\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "    text_tokens = tokenizer(TEXT_PROMPTS).to(device)\n",
    "    text_features = model.encode_text(text_tokens)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1d58e",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Wczytanie obraz√≥w i generowanie embedding√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7cb976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znaleziono 100 obraz√≥w w data/staging\n",
      "Przetworzono 10/100\n",
      "Przetworzono 20/100\n",
      "Przetworzono 30/100\n",
      "Przetworzono 40/100\n",
      "Przetworzono 50/100\n",
      "Przetworzono 60/100\n",
      "Przetworzono 70/100\n",
      "Przetworzono 80/100\n",
      "Przetworzono 90/100\n",
      "Przetworzono 100/100\n"
     ]
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model ju≈º utworzony wy≈ºej: `model, _, preprocess = open_clip.create_model_and_transforms(...)`\n",
    "model.to(device).eval()\n",
    "\n",
    "# FP16 na MPS/CUDA, FP32 na CPU\n",
    "if device.type in (\"mps\", \"cuda\"):\n",
    "    model.half()\n",
    "    IMG_DTYPE = torch.float16\n",
    "    amp_ctx = nullcontext()           # NIE u≈ºywamy autocast na MPS\n",
    "else:\n",
    "    model.float()\n",
    "    IMG_DTYPE = torch.float32\n",
    "    amp_ctx = nullcontext()\n",
    "\n",
    "# tekst te≈º w tym samym dtype\n",
    "with torch.no_grad():\n",
    "    text_tokens = tokenizer(TEXT_PROMPTS).to(device)\n",
    "    text_features = model.encode_text(text_tokens)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features.to(IMG_DTYPE)  # sp√≥jno≈õƒá dtype\n",
    "\n",
    "# --- pƒôtla po plikach ---\n",
    "records = []\n",
    "files = sorted([p for p in DIR_STAGING.rglob(\"*\")\n",
    "                if p.suffix.lower() in [\".jpg\",\".jpeg\",\".png\",\".tif\",\".tiff\"]])\n",
    "\n",
    "print(f\"Znaleziono {len(files)} obraz√≥w w {DIR_STAGING}\")\n",
    "\n",
    "for i, path in enumerate(files):\n",
    "    try:\n",
    "        image = preprocess(Image.open(path).convert(\"RGB\")).unsqueeze(0)\n",
    "        image = image.to(device=device, dtype=IMG_DTYPE)\n",
    "\n",
    "        with torch.no_grad():         # bez autocast na MPS\n",
    "            image_features = model.encode_image(image)\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "            probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)[0].tolist()\n",
    "\n",
    "            best_label = LABELS[probs.index(max(probs))]    \n",
    "            records.append({\n",
    "            \"filename\": path.name,\n",
    "            \"label_pred\": best_label,\n",
    "            \"p_prl\": probs[1],\n",
    "            \"p_post1989\": probs[2],\n",
    "            \"p_pre1945\": probs[0],\n",
    "        })\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Przetworzono {i+1}/{len(files)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"B≈ÇƒÖd w pliku {path.name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ebb67",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Zapis wynik√≥w i logu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45a1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Zapisano wyniki: outputs/clip_zero_shot_results.csv (100 rekord√≥w)\n"
     ]
    }
   ],
   "source": [
    "# 5Ô∏è‚É£ Zapis wynik√≥w i logu\n",
    "\"\"\"\n",
    "Zapisuje wyniki zero-shot do outputs/ oraz loguje etap w logs/runlog.jsonl.\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "out_csv = DIR_OUT / \"clip_zero_shot_results.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"üìÑ Zapisano wyniki: {out_csv} ({len(df)} rekord√≥w)\")\n",
    "\n",
    "# rejestracja runu\n",
    "log_entry = {\n",
    "    \"run_id\": run_id,\n",
    "    \"stage\": \"clip_zero_shot\",\n",
    "    \"n_files\": len(df),\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"precision\": \"fp16\",\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "}\n",
    "Path(\"logs\").mkdir(exist_ok=True)\n",
    "with open(\"logs/runlog.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(log_entry, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef298dc",
   "metadata": {},
   "source": [
    "### 6Ô∏è‚É£ PodglƒÖd pr√≥bki wynik√≥w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1601cab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>p_prl</th>\n",
       "      <th>p_post1989</th>\n",
       "      <th>p_pre1945</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0196.jpg</td>\n",
       "      <td>do 1944</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.161621</td>\n",
       "      <td>0.770996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0022.jpg</td>\n",
       "      <td>PRL 1945‚Äì1989</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.199707</td>\n",
       "      <td>0.058136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0136.jpg</td>\n",
       "      <td>PRL 1945‚Äì1989</td>\n",
       "      <td>0.825195</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>0.056152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0256.jpg</td>\n",
       "      <td>do 1944</td>\n",
       "      <td>0.228638</td>\n",
       "      <td>0.130249</td>\n",
       "      <td>0.641113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0253.jpg</td>\n",
       "      <td>PRL 1945‚Äì1989</td>\n",
       "      <td>0.560547</td>\n",
       "      <td>0.148560</td>\n",
       "      <td>0.290771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename     label_pred     p_prl  p_post1989  p_pre1945\n",
       "83  0196.jpg        do 1944  0.067383    0.161621   0.770996\n",
       "53  0022.jpg  PRL 1945‚Äì1989  0.742188    0.199707   0.058136\n",
       "70  0136.jpg  PRL 1945‚Äì1989  0.825195    0.118835   0.056152\n",
       "45  0256.jpg        do 1944  0.228638    0.130249   0.641113\n",
       "44  0253.jpg  PRL 1945‚Äì1989  0.560547    0.148560   0.290771"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6Ô∏è‚É£ PodglƒÖd pr√≥bki wynik√≥w\n",
    "\"\"\"\n",
    "PodglƒÖd kilku pierwszych wynik√≥w klasyfikacji.\n",
    "\"\"\"\n",
    "\n",
    "df.sample(5, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv MetaLogic)",
   "language": "python",
   "name": "metalogic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
